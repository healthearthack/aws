name: ‚ôæÔ∏è AI Token Improvement Loop

on:
  push:
    branches: [ main ]
  workflow_dispatch: # Allows manual triggering for a "System Health Check"

jobs:
  optimize-and-audit:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Essential: Allows the AI bot to push fixes back to the repo

    steps:
      - name: üõ∞Ô∏è Step 1: Initialize Environment
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Pulls full history for the audit trail

      - name: üêç Step 2: Set up Python Engine
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: ü§ñ Step 3: Execute AI-Audit & Healing
        run: |
          python -c "
          import json, os, glob
          
          # ARCHITECTURE: DYNAMIC PATH FINDING
          # We use glob to find the file regardless of folder names or spaces.
          # The '**' searches recursively through all subdirectories.
          files = glob.glob('**/tokens.json', recursive=True)
          
          if not files:
              print('‚ùå CRITICAL: tokens.json not found in the repository.')
              exit(1)
          
          path = files[0]
          print(f'‚úÖ AI Target identified: {path}')

          with open(path, 'r') as f:
              data = json.load(f)
          
          # ARCHITECTURE: THE HEALING LOGIC
          # This function crawls your JSON and standardizes data (e.g., Hex codes to Uppercase)
          def auto_heal(obj):
              if isinstance(obj, dict):
                  return {k: auto_heal(v) for k, v in obj.items()}
              elif isinstance(obj, list):
                  return [auto_heal(i) for i in obj]
              elif isinstance(obj, str) and obj.startswith('#'):
                  return obj.upper() # Ensures #ffffff becomes #FFFFFF
              return obj
          
          improved_data = auto_heal(data)
          
          # ARCHITECTURE: CLEAN RE-WRITING
          # Saves the 'healed' version back to the original file with clean indentation
          with open(path, 'w') as f:
              json.dump(improved_data, f, indent=2)
          "

      - name: ‚ö° Step 4: Speed Optimization (Minify)
        run: |
          # Finds the path again for the shell environment
          TARGET_FILE=$(find . -iname "tokens.json" | head -n 1)
          # Creates a production-ready 'tokens.min.json' at the ROOT of the repo
          python -c "import json; data = json.load(open('$TARGET_FILE')); json.dump(data, open('tokens.min.json', 'w'), separators=(',', ':'))"

      - name: üîÑ Step 5: Close the Loop (Self-Commit)
        run: |
          # This is the 'Forever Loop' mechanism. 
          # It detects if the AI made any changes and pushes them back automatically.
          git config --global user.name 'Design-System-AI'
          git config --global user.email 'actions@github.com'
          git add .
          
          # Only commit if there are actual improvements detected
          if git diff --staged --quiet; then
            echo '‚ú® No improvements needed. System is healthy.'
          else
            git commit -m 'ü§ñ AI-System: Healed formatting & updated production build'
            git push
            echo 'üöÄ Improvements pushed to repository.'
          fi
